涵哥：你好啊。可以听见吗？你好。

面试官：能听清我说话。吗？

涵哥：能听到的。

面试官：可以听见，是吧

涵哥：对的

面试官：可以方便打开一下摄像头吗？

涵哥：方便的诶

面试官：这边那先辛苦你做一下这个，简单介绍一下吧。

涵哥：好的好的啊。面试官你好，我叫焦欣意，然后目前从事数据开发工作的话，差不多是 5 年多 5 年左右的开发经验，然后之前的话

面试官：稍等一下，稍等一下。好的，

面试官：现在还现在能听我说话吗？

涵哥：嗯，可以的。

面试官：OK 的，是吧，好好的，那你辛苦，你再介绍一下吧。

涵哥：好的，然后面试官你好，我叫焦欣意，然后目前从事数据开发工作的话，差不多是 5 年多的开发经验。之前的话主要做的是一些电商数据这一块做得比较多，然后像其他部分的话，主要做的是一些像实时离线都是有涉及到的。然后实时部分的话主要是 Flink SQL、 Flink jar这一块做得比较多，然后离线的话主要就是 Hive SQL 这一块，然后云平台的话就是阿里云体系的Dataworks、 datafin 有过一些接触，然后像是这些 datahub 这块也会有接触。对，然后以上的话就是我的一个简单的自我介绍，谢谢面试官。

面试官：是能听见吗。

涵哥：能听到的

面试官：也不太清楚，我那边好像听不太清你说的话好像啊。

涵哥：我可能是我这边是手机那个什么比较卡，那这样吧，我先把那个视频关一下，您看一下会不会好一点。

面试官：现在可以了，现在也差不多。

涵哥：好像OK，没问题。

面试官：现在可以，声音可能要需要你稍微大一点，你 5 年，我看一下你上份工作，你是在一家公司是一直工到工作到现在是吗？

涵哥：对的。

面试官：你这家公司是在深圳是吧。

涵哥：对，但是有的时候会出差，会去别的地方。

面试官：你们是做的是外包还是做的是自研的。

涵哥：主要做的是外包，做的是一些项目。

面试官：是外包项目，是吧？对，我看一下你最近的，你最近做的那个项目，这是离线的吗？

面试官：最后这个横商的那个应该算是离线实时都有。

面试官：就是这个横算支付平台这个。项目

涵哥：对，它其实应该都是有都有。

面试官：嗯，这个项目你可以简单介绍一下。

涵哥：可以，这个项目的话它本身它是 Lambda 的架构，然后大多数的数据的话它其实都是离线那边做计算，然后实时的数据的话相对来说会少一些。实时的数据基本上是针对于当天的营收，当天的效能这一块做一些实时统计。这是第一个，第二个的话离线这边大多数都是在基于会员主题、销售主题、财务主题，然后库存主题这几个方面进行展开，然后做一些指标上的求和跟计算。实时这边的话主要针对于线下门店的销售数据，然后各个货品中转仓的这种流动率、流通性这些做一些计算，数据源的话主要是 MySQL 跟 SQL Server 这两个。还有一部分的话是几台 Oracle 的财务数据库，我们会把这部分的数据通过数据管道，相当于是接出来，接出来之后在数仓当中再去做数据的一个分析，跟数据的一个分层，然后最后的话报表可视化用的是fine report，就是翻量的一些产品用得比较多。

面试官：基本上像你们在这个项目里面就是整体的，就是它的一个数据链路，它是有几条数据链路，它整个的一个数据流向是什么样子的啊？

涵哥：整个的数据流向，整个的数据流向的话就是通过几个点，第一个就是说 MySQL 跟 SQL Server 的数据

面试官：基本上像你们在这个项目里面就是整体的，就是它的一个数据链路，它是有几条数据链路，它整个的一个数据流向是什么样子的啊？

涵哥：整个的数据流向，整个的数据流向的话就是通过一几个点，第一个就是说 MySQL 跟 SQL Server 的数据，然后离线就是 t+1， t +1，用 data 叉，最开始用 git 叉进行数据同步理解，那个实时数据的话就是用的是 Flink CDC，然后 MySQL 用的就是 blog，然后 SQL Server 用的是那个增量日志的方式。然后 Oracle 的话用的是 OGG 做的数据同步。这是数，对，这是大概大致的数据链路，相当于是。

面试官：行，好的，你们是刚才说到你们用那个实时的话，你们用的实时的数据链路，它从开始一直到你们实时主要是做哪一块的？刚才说到说那个有那个什么数据统计，还有什么。

涵哥：主要是做的这几个东西，第一个是线下门店的销售数据，当天的营收占比，这部分的数据链路的话就是MySQL，然后 Flink CDC，然后Flink，然后下游的话是 Doris 基，然后中间的话中间结果有的时候是纯Kafka，有的时候是直接是Hbase。

面试官：好，你之前你们刚才说到用那个Flink，你们是，你是直接写 Flink SQL 吗？

涵哥：Flink SQL 跟 Flink 架都会写。

面试官：都会有，是吧？你们对于就是有没有关于一些这个实时的一些稍微复杂一点的这些聚合统计啊？聚合计算？项目里面

涵哥：稍微复杂一点的，像那些比如说常见的这种基于日志的统计，就是流量曝光，然后PV、 UV 这些东西，这是第一个，第二个的话实时链路的话我们会做一个敏感用户敏感词的检测，就是用户发言数据，用户评论数据这一块也是实时去做的，就是会分为这种政治敏感性、反动瑟琴、邪教传播，然后发票交易这些东西也是通过实时的，这些通过实时流去做的，窗口统计，然后去下游的 Redis 的那个数据库里面去查，然后去返回各个事故等级结果。然后再往下游去发，这是第二个，然后第三个的话就是有一些实时配置数据，是前端传一个模板过来，然后我们后端的话就是 Flink 这边根据它的这个配置信息去做预警，主要就是分为这三块，就是我们的事实。

面试官：好的，嗯。日志文件你们就是你在写sql的时候，你是，就是有没有说是有关于，比如说涉及的数据，比如你是这种涉及的数据涉及到多张表的数据，你没在里面去做一些简单的一些聚合，然后但是深层次的开发，比如说像一些类似于，比如说把一些报表开发出来，然后再通过像finebi东西，通过展示出来有没有涉及到，比如说多张表关联的这种，在Flink，你写 Flink SQL 的时候

涵哥： Flink SQL 我们一般不会用多张表做关联。一般情况下这种多表的连接就是多条流表的连接，然后再做聚合，做一些窗口。这些东西我们都是写java代码，就是两条流接出来，接出来之后，然后把这两条流不管是你的 right join 还是说它 join 到一起去，然后下游的话就是点直接就是 Windows 开窗计算，然后reduce，然后 process 再往下的话就是看加不加测数据流，然后给它数据结果，然后或者往下游的存储介质里面去写，大多数情况应该是这样的，我们 Flink SQL 只会去做一些简单的 ETL 的机械任务。

面试官：OK，也就说你们是你们在做的时候和 MySQL 是用的是做一些简单的计算，简单的 ETL 对单张表，然后其他的是通过流的方式。

涵哥：对，大多数是这样的，我们对sql就是怎么说呢？我们这边大多数都是 Java 开发出身，所以说大多数情况更愿意写代码，然后上架传jar包，然后提平台这样的开发模式。

面试官：OK，也就说你们行的，之前你说你有用过那个阿里云的，你对，针对阿里云，你有没有在阿里云上去做一些关于像实时的你项目？没有用到阿里云吗？

涵哥：阿里云的那个流式数据处理平台我们用过，我们也有那个平台，但是我们用得比较少，也买了授权，就是阿里云的 Dataworks 跟那个流处理平台都有。

面试官：你之前是有像那个 CK 的话，就 clickhouse 这一块，这个数据库你之前是有用到吗。

涵哥：有用到，但相对会少一点，我们现在用 Doris 用得多一点。 CK 的话之前有一些大宽表，很大的宽表就那种四五百个，四五百字段的那种，之前做一些保险上面会把这些表的话存在 CK 里面，然后也是分布式的表，就是它的查询性能确实很快，就单表查询性能非常的快。当时为了支撑前端的一些领导的决策看板，然后去用的。

