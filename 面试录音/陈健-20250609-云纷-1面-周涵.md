面试官：自我介绍吧。

涵哥：好的好的。嗯，各位面试官，大家下午好，我叫陈建，然后目前从事数据开发的话，主要的话有 4 年多的开发经验，将近 5 年。然后最近的话主要做的是一些数据开发类的工作，然后Java、Python、 SQL 这块基本上都还算OK，然后这两年的话实时接触的会多一些Flink，主要做的是一些 Flink 的数据开发工作，然后有 Flink SQL， Flink Java 都有一些开发经验嗯。编程语言的话主要接触的比较多的就是Java。 Python 行业的话主要做的就是电商零售这一块，接触的会多一些。以上的话就是我的一个简单的自我介绍，谢谢面试官。

面试官：呃。好的，那就是要不你介绍一下最近的这个项目，就你在这里面主要是负责具体的哪一块？

涵哥：嗯，可以的，最近做的就是一个乐购的数据分析平台，然后甲方的话是衣帽鞋、衣帽服装，然后箱包企业，然后我在这里面主要做的就是针对于他们的这种线下门店做一些数据开发工作，然后主要分为的话是离线部分跟实时部分两个方面。然后离线这边的话主要就是 Hive SQL 这边为主，就是引擎的话用的是Spark，然后 SQL 是 Hive SQL，然后实时这边的话主要的就是Flink， Flink sql跟flink jar为主做主要针对的就是他们的这些零售板块，跟这个线下门店的数据做一些汇总分析，做一些数据加工，会做得多一些。然后主要的业务域就是 c 端零售， c 端零售加上一部分 b 端的供应链的数据会做得稍微多一些。主要接触的就是实时这边的一些业务逻辑会算，会做一些处理，大致的流程是这样，然后数据库的话是 SQL Server 为主， SQL Server、MySQL，然后 PG 这三大数据库为主。做数据抽取工具的话是用的 sitino 来做的，因为这是个新项目。然后大多数的技术组件都是比较新的。

面试官：好，就是刚才有提到说有用在这里面有用到Flink，然后主要是做了哪些工作？

涵哥：Flink 的话其实主要做的就是一些基于零售的分析，包括说基于零售的看板，然后实时看板，然后目标达成率、商品主题分析，然后从品类到大类的数据赚取，主要实施部分是这些，还有一部分的话就是基于财务的报账提报税。然后这一块的数据也是实时的，但是这块的数据链路可能会比较长，就是数据加工指标大概是每 30 分钟更新一次，因为供应商那边报过来的数据有的时候延迟就比较严重，所以说是每 30 秒、每 30 分钟同步一次，然后其实也不能够算实时了。对。

面试官：好呀，那在这个项目当中你觉得就是一个比较，你觉得比较困难的地方，然后你解决，你是怎么解决它的。

涵哥：呃？比较困难的地方其实就是补数，就是实时补数，因为有很多的这种门店数据，它的数据的上报，或者说那些 IoT 数据的上报它是比较慢的。然后有的时候可能会出现跨天的这种情况，如果说数据跨天上传的话，就会存在实时数据跟离线数据对不上这个情况，那这种情况下的话，最开始的时候其实发现的也是比较晚的，因为这部分数据就是说实话，它相对来说不太容易被发现，而且如果说那种是非大单的这种情况，其实有的时候可能发现不了，因为最后的结果有一部分会做一些四舍五入，然后总成交额可能是上百万，或者是有的时候接近千万的这种成交额，可能像这种千万的数据可能就发现不了了。所以说当时发现了这个问题之后，就是用实时去补了一下离线的数据，然后去做数据加工，然后去把这个离线的数据的所在分区做了一个重新固化跟刷新，就是重新做了一个override，就是这一块的话，当时是发现之后，嗯，比较难处理的一个部分。

面试官：好呀。诶，威虎你那边有什么问题吗？

面试官：嗯，你刚才提到的是那个离线那边需要补诉，对吧

涵哥：对。

面试官：就是说你们离线也是用的 Hive 和 Hadoop 那一套，对吧？

涵哥：对，就是 Hadoop 体系。

面试官：然后你指的补数就是说，比如说这个数据可能是，比如说是 8 号，今天是 9 号，可能是 8 号的数据是，你的意思是他可能 9 号才到啊。对，所以你们在统计的时候， 8 号的指标就会少一部分数据啊。对，这一部分你们是通过实时把这个数据补过去的吗啊？对，就补到李现那边。对，实时就是查哪块缺，你们那个 Hive 任务每天调度的时候是在几点调度？

涵哥：12 点 12: 10 以后， 12: 10 以后有几个任务是 12 点前就可以调了？因为业务系统就是有几个业务系统，有几个 CMS 的那个业务系统是 11 点左右它就关了，也不能说关了，就是它不会再进数了，就是肯定不会进数了。所以说有的一部分任务会在 12 点之前就开始跑批，然后大多数任务都是 12 点之后开始跑。

面试官：呃。你们那个 IoT 的数据大概延迟会多久？就你说跨天，它可能跨天要延迟多久？

涵哥：有的延迟可能会达到两三天。就是有一部分的数据延迟，因为有一部分的外勤车辆，他如果说去一些山区什么地方的话没信号，因为他用的是 2G 的 IoT 的那个信号协议，他没信号，他数据是上传不上来，他在本地积压，然后有信号他才会推上来。所以说有的时候会就是延迟，挺严重的。

面试官：如果你的数据会延迟两三天的话，那这意味着你的你最后输出的结果必须要到两三天之后才能看到一个准确的。

涵哥：不是这样讲，应该说它延迟的数据会导致离线那边对不上，就是离线跟当天的实时它算出来不一样。就是从以后的角度上来说，比如说他 6 号他双端是对得上的， 7 号也对得上， 8 号就对不上了， 8 号的业务库跟当前的数据库就是数据中台数据就对不上了。

面试官：你们那个 IoT 的设备，就比如说是车上的那个 IoT 的数 IoT 数据吗？是车辆的那个传感器上面的数据，

涵哥：对，车辆传感器的那些。

面试官：然后它通过那个蜂窝移动网络，也就是那个移动网络传到你们的可能是公网上的一个采集点，然后你们是这样拿的数据。

涵哥：对的，它有一个信号，它有一个那个APP，就车上有个APP。

面试官：然后这个数据是到你们可能是云上某一个采集店，然后这个你们是拿这个数据同时去做离线和实施，对吧。

涵哥：呃？对，同时去做离线跟实时，是。

面试官：那同时去做离线和实时的话，如果你这个数据延迟了，代表你的实时和离线都是延迟的。

涵哥：不，不是这个意思，它我们是 Lambda 的架构，离线算，离线实时算，实时是只算当天这个时候它数据是对得上的，只是后面的数据它插到业务库里面会导致数据库，会导致数据中台跟业务系统它对不上。

面试官：但是你说你的数据延迟两三天，就比如说我，你要算今天九号的数据，要到十二号才到，你，你怎么能保证今天的数据最后实时算出来是准确的呢？

涵哥：他如果说这个延迟数据他不入库的情况下，那从数据库的角度，就是后端数据库的角度跟数据中台的角度上来说，这个时候数据是一样的，这个是没有问题的。然后 7 号他也没来，那说明他也是一样的。但是 8 号这个数据库，这个数据他插入了业务数据库，但是这个时候数据中台的数据他已经跑完批了，那这个时候才会对不上。

面试官：我理解下来，他的意思就是说他们是就是把这个数据从业务数据库统一拉到数据中台，然后去做一个展示。那在这个数据没有来之前，他跟业务数据库是对得上的，因为你也不知道会不会有数据延迟过来，你就说还没有发生的时候，你就这个时候看到的数据是你觉得是，但是有可能说过两三天以后又有新的数据插入了。然后如果这个时候数据中台不做更新的话，它就跟业务数据库对不上。

涵哥：对，是的。

面试官：OK。然后我们看一下，就是你项目上写的那个第一个项目吧。我稍等，我看一下。关于刚才那个问题，就是比方说你提到说你的解决方案是补数，那就是可以，我是不是可以这么理解？就是说如果你那边 flink 就是说发现它有一个跟以前不一样的数据，然后你就重新计算一遍。

涵哥：会针对于他所在的那个分区重新计算一遍，不会所有的都重算，只针对于缺数的那个分区重算。

面试官：那你是怎么样知道说它这个数据是通过什么特征知道说它这个数据是一个延迟的数据。

涵哥：我用 flat CDP 去抓这个数据，比如说我一个 Flink CDC，我比如说今天是6月 9 号，6月 9 号来了一个非6月 9 号的数据，那我是不是可以判断出这个数据它是之前的数据呢？那它比如说6月 9 号才来了之前的 binlog 数据，那我们就可以认为6月 7 号或者说6月 8 号所在的那个分区数据它是有问题的，它的数据是少的。

面试官：但它也不一定是新增，它也有可能是更新啊。

涵哥：那如果说是新增或者说更新的话，我们可以根据它那个 OP 的那个字段去取它是一个插入数据还是一个 update 数据？

面试官：OK，那你那个业务数据库是MySQL，是吗？

涵哥：对，是mysql。

面试官：好的，然后我可以介绍一下，就是你这个 logo 数据分析平台刚刚讲的是这个项目吗啊？刚刚讲的就是这个项目啊。所以你们那离线那边是用那个 Situno 把那个 MySQL 的数据导入到那个 Hive 里面吗。

涵哥：对的，是的，situno

面试官：那这个项目它上游数据量大概有多少呢？

涵哥：上游数据量其实业务数据不算特别多，业务数据每天加起来六七十个g，但是日志数据就是前端埋点，加上 IoT 设备数据，每天加起来能有将近八九百个g。

面试官：你们集群大概几个节点啊？就是离线，就是整个集群的架构，就是离线和实时资源怎么划分的。

涵哥：是这样的，离线实时这边的话分为两个队列，雅思上面的话分了两个队列出来。然后他的这个队列资源的话一共是 17 台服务器， 17 台物理机，然后内存就是每台机器是256的内存，加上 10 个 t 的固，那个机械硬盘，然后离线的占比那个是70%，然后实时这边的话是15%，剩下的 15% 是动态资源。

面试官：整个集群这个部署和运维这个工作你有。

涵哥：参与吗啊？有参与一部分，因为用的是CDH。

面试官：OK，就是当初这 Kafka 集群或者说 Flink 集群搭建的时候你也有参与，对吧

涵哥：有参与的 Kafka 集群。你就 Kafka 集群这块你们是怎么配置的？就比如说啊？节点划分。

涵哥：Kafka 之类的， Kafka 节点的话我们是 9 个节点，就是 Kafka 一共就 9 个节点，就是一共 17 台机器，不是所有机器上都有 Kafka 的，只有 9 个节点上有Kafka。

面试官：跟你们 Kafka 是单独的 9 个节点，这 9 个节点上只跑Kafka，没有其他。

的服务，对吧？

涵哥：也是放在 CDH 里面的，只是说不是所有的 CDH 的节点都有Kafka，只有 01 ~ 09 有Kafka。

面试官： CDH 你们部署之后应该是可以选择哪一台机上哪台机器上跑哪一台服务，所以你们是在那 9 个 CDS 节选节点上面只跑了Kafka，对吧。

涵哥：也有其他组件，就是比如说一共 17 台节点， 17 台节点它肯定都是 data NODE，这是肯定的，但是只有 9 台节点里面有Kafka。

面试官：17 台节点全都有 data NODE。

涵哥：对，就是都有 HDFS 的 data NODE，但是只有 9 台节点里面是装了 Kafka 的这个组件的。

面试官：然后因为你们服务器全都是机械磁盘，因为机械磁盘性能是相对来说是比较低的。然后你们那个 data NODE 和那个 HDA SSS，你们在就是都有的节点上你们有做过什么区分吗？对，因为机械磁盘的性能本身是有限的，你们的流量又比较大，可能会有磁盘性能的问题，所以这个你们在有碰到过。

涵哥：首先的话我们开了那个纠删码，纠删码可以缓解一部的那种，就是允许一部分的数据出现错误，然后不影响整体的数据效能。就是 HDFS 的纠删码，然后配了一个高可用的 name NODE，就是双 name NODE，然后雅恩也是配了一个两个 resource manager，然后 Hbase 的话是两个 Hmaster 做主备切换。

面试官：那你们的 Kafka 有配置多目录吗。

涵哥：我们 Kafka 没有配置多目录，我们就配了一个 SSH

面试官：就平时比如说集群的一些。监控指标这这边你们平时有在看吗？就是你这边有在看吗？就比如说哪些指标可能比较异常，就需要去关注一下之类的。

涵哥：有在看它也会发邮件跟发警报的，你比如说 IO 性能达到峰值 85% 以上，持续 3 分钟之后它就会发一个邮件出来。

面试官：OK，这部分你也有在做，对吧啊？

涵哥：对，这部分是有在做的，你一部分的运维工作是有在参与的。

面试官：我想了解一下，就你现在还在职吗啊？

涵哥：已经离职了，刚离职不到一周。

面试官：你现在在上海。

涵哥：啊？现在不在上海，现在的话之前的项目组在北京，所以说现在还在北京，只是在看上海的机会，OK。

面试官：那可能就是因为如果说你在上海的话，就是可能会希望你能来公司一趟，就是二面。

涵哥：咱们可以约线上就视频什么的，包括共享桌面都没问题的，主要是太远了，就是我还是希望能够确定下来，我直接就 OK 了，就直接搬家过去了啊。

面试官：明白，对，因为我们这边时间有限，就是我们后面还有一个会议，就是那要不然今天先这样，然后续的话 HR 会跟您联系。

涵哥：好的，好的，没问题，谢谢，  
面试官：好，拜拜。

涵哥：好，拜拜，谢谢各位领导。